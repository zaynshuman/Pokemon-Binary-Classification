{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Preparing the Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('Pokemon_processed.csv', delimiter=',',skiprows =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float':'{:0.2f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.00 49.00 49.00 65.00 65.00 45.00 0.00]\n",
      " [60.00 62.00 63.00 80.00 80.00 60.00 0.00]\n",
      " [80.00 82.00 83.00 100.00 100.00 80.00 0.00]\n",
      " [80.00 100.00 123.00 122.00 120.00 80.00 0.00]\n",
      " [39.00 52.00 43.00 60.00 50.00 65.00 0.00]\n",
      " [58.00 64.00 58.00 80.00 65.00 80.00 0.00]\n",
      " [78.00 84.00 78.00 109.00 85.00 100.00 0.00]\n",
      " [78.00 130.00 111.00 130.00 85.00 100.00 0.00]\n",
      " [78.00 104.00 78.00 159.00 115.00 100.00 0.00]\n",
      " [44.00 48.00 65.00 50.00 64.00 43.00 0.00]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 7)"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,:-1]\n",
    "Y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data \n",
    "\n",
    "mean = X.mean(axis = 0)\n",
    "std = X.std(axis = 0)\n",
    "X = (X - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.95 -0.92 -0.80 -0.24 -0.25 -0.80]\n",
      " [-0.36 -0.52 -0.35 0.22 0.29 -0.29]\n",
      " [0.42 0.09 0.29 0.83 1.01 0.40]\n",
      " [0.42 0.65 1.58 1.50 1.73 0.40]\n",
      " [-1.19 -0.83 -0.99 -0.39 -0.79 -0.11]\n",
      " [-0.44 -0.46 -0.51 0.22 -0.25 0.40]\n",
      " [0.34 0.15 0.13 1.11 0.47 1.09]\n",
      " [0.34 1.57 1.19 1.75 0.47 1.09]\n",
      " [0.34 0.77 0.13 2.64 1.55 1.09]\n",
      " [-0.99 -0.96 -0.28 -0.70 -0.28 -0.87]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (800, 6)\n",
      "Y:  (800,)\n"
     ]
    }
   ],
   "source": [
    "print('X: ',np.shape(X))\n",
    "print('Y: ',np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X: train/test and Y: train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  65.0\n",
      "Train:  35.0\n",
      "Test:  30.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate total number of Legendary Pokemon in test/train split \n",
    "\n",
    "print('Total: ', sum(dataset[:,6]))\n",
    "print('Train: ',sum(y_train))\n",
    "print('Test: ',sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4, input_dim = len(X[0,:]), activation = 'relu'))\n",
    "model.add(Dense(1, input_dim = len(X[0,:]), activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_47 (Dense)            (None, 4)                 28        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "13/13 [==============================] - 1s 6ms/step - loss: 0.6141 - accuracy: 0.7350\n",
      "Epoch 2/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5763 - accuracy: 0.7600\n",
      "Epoch 3/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5486 - accuracy: 0.7800\n",
      "Epoch 4/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7950\n",
      "Epoch 5/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.8100\n",
      "Epoch 6/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.8175\n",
      "Epoch 7/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.8175\n",
      "Epoch 8/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.8175\n",
      "Epoch 9/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8200\n",
      "Epoch 10/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4175 - accuracy: 0.8275\n",
      "Epoch 11/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8350\n",
      "Epoch 12/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3927 - accuracy: 0.8375\n",
      "Epoch 13/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8400\n",
      "Epoch 14/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8425\n",
      "Epoch 15/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8475\n",
      "Epoch 16/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8575\n",
      "Epoch 17/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8625\n",
      "Epoch 18/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8675\n",
      "Epoch 19/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8675\n",
      "Epoch 20/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8675\n",
      "Epoch 21/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8775\n",
      "Epoch 22/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8875\n",
      "Epoch 23/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8950\n",
      "Epoch 24/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.8975\n",
      "Epoch 25/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.9000\n",
      "Epoch 26/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.9000\n",
      "Epoch 27/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.9000\n",
      "Epoch 28/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.9000\n",
      "Epoch 29/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9025\n",
      "Epoch 30/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9050\n",
      "Epoch 31/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9050\n",
      "Epoch 32/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.2554 - accuracy: 0.9075\n",
      "Epoch 33/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2512 - accuracy: 0.9125\n",
      "Epoch 34/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2472 - accuracy: 0.9125\n",
      "Epoch 35/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9125\n",
      "Epoch 36/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2395 - accuracy: 0.9125\n",
      "Epoch 37/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2360 - accuracy: 0.9125\n",
      "Epoch 38/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9125\n",
      "Epoch 39/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9125\n",
      "Epoch 40/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9125\n",
      "Epoch 41/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9125\n",
      "Epoch 42/256\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.2202 - accuracy: 0.9125\n",
      "Epoch 43/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2173 - accuracy: 0.9125\n",
      "Epoch 44/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9125\n",
      "Epoch 45/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2118 - accuracy: 0.9125\n",
      "Epoch 46/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2090 - accuracy: 0.9125\n",
      "Epoch 47/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.2065 - accuracy: 0.9125\n",
      "Epoch 48/256\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.2039 - accuracy: 0.9125\n",
      "Epoch 49/256\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2012 - accuracy: 0.9125\n",
      "Epoch 50/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1984 - accuracy: 0.9125\n",
      "Epoch 51/256\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1957 - accuracy: 0.9125\n",
      "Epoch 52/256\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1930 - accuracy: 0.9125\n",
      "Epoch 53/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9125\n",
      "Epoch 54/256\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1874 - accuracy: 0.9125\n",
      "Epoch 55/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9125\n",
      "Epoch 56/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9125\n",
      "Epoch 57/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9125\n",
      "Epoch 58/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9125\n",
      "Epoch 59/256\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1753 - accuracy: 0.9125\n",
      "Epoch 60/256\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1731 - accuracy: 0.9125\n",
      "Epoch 61/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1710 - accuracy: 0.9125\n",
      "Epoch 62/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.9125\n",
      "Epoch 63/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9125\n",
      "Epoch 64/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9125\n",
      "Epoch 65/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9125\n",
      "Epoch 66/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9125\n",
      "Epoch 67/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9125\n",
      "Epoch 68/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9125\n",
      "Epoch 69/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1584 - accuracy: 0.9125\n",
      "Epoch 70/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.9125\n",
      "Epoch 71/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1562 - accuracy: 0.9125\n",
      "Epoch 72/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9125\n",
      "Epoch 73/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9125\n",
      "Epoch 74/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9125\n",
      "Epoch 75/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1524 - accuracy: 0.9125\n",
      "Epoch 76/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1514 - accuracy: 0.9125\n",
      "Epoch 77/256\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.1505 - accuracy: 0.9125\n",
      "Epoch 78/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9125\n",
      "Epoch 79/256\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1487 - accuracy: 0.9125\n",
      "Epoch 80/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1479 - accuracy: 0.9125\n",
      "Epoch 81/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9125\n",
      "Epoch 82/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1463 - accuracy: 0.9125\n",
      "Epoch 83/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9125\n",
      "Epoch 84/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1446 - accuracy: 0.9125\n",
      "Epoch 85/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9125\n",
      "Epoch 86/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1431 - accuracy: 0.9125\n",
      "Epoch 87/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1423 - accuracy: 0.9125\n",
      "Epoch 88/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9125\n",
      "Epoch 89/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9125\n",
      "Epoch 90/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1400 - accuracy: 0.9125\n",
      "Epoch 91/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9125\n",
      "Epoch 92/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1384 - accuracy: 0.9125\n",
      "Epoch 93/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1374 - accuracy: 0.9125\n",
      "Epoch 94/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9125\n",
      "Epoch 95/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9125\n",
      "Epoch 96/256\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1341 - accuracy: 0.9125\n",
      "Epoch 97/256\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.1330 - accuracy: 0.9125\n",
      "Epoch 98/256\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1317 - accuracy: 0.9125\n",
      "Epoch 99/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1306 - accuracy: 0.9125\n",
      "Epoch 100/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1294 - accuracy: 0.9125\n",
      "Epoch 101/256\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1283 - accuracy: 0.9150\n",
      "Epoch 102/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1266 - accuracy: 0.9225\n",
      "Epoch 103/256\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1250 - accuracy: 0.9300\n",
      "Epoch 104/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9325\n",
      "Epoch 105/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9350\n",
      "Epoch 106/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9400\n",
      "Epoch 107/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9400\n",
      "Epoch 108/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9450\n",
      "Epoch 109/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.9500\n",
      "Epoch 110/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.9475\n",
      "Epoch 111/256\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1109 - accuracy: 0.9525\n",
      "Epoch 112/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1093 - accuracy: 0.9525\n",
      "Epoch 113/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1077 - accuracy: 0.9525\n",
      "Epoch 114/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9525\n",
      "Epoch 115/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1047 - accuracy: 0.9600\n",
      "Epoch 116/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9575\n",
      "Epoch 117/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9625\n",
      "Epoch 118/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9600\n",
      "Epoch 119/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9625\n",
      "Epoch 120/256\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0985 - accuracy: 0.9650\n",
      "Epoch 121/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0974 - accuracy: 0.9650\n",
      "Epoch 122/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9675\n",
      "Epoch 123/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9675\n",
      "Epoch 124/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9700\n",
      "Epoch 125/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.9700\n",
      "Epoch 126/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9700\n",
      "Epoch 127/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9700\n",
      "Epoch 128/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 0.9700\n",
      "Epoch 129/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9700\n",
      "Epoch 130/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9700\n",
      "Epoch 131/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9700\n",
      "Epoch 132/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.9700\n",
      "Epoch 133/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9700\n",
      "Epoch 134/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9700\n",
      "Epoch 135/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9700\n",
      "Epoch 136/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9700\n",
      "Epoch 137/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9675\n",
      "Epoch 138/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9675\n",
      "Epoch 139/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.9675\n",
      "Epoch 140/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9675\n",
      "Epoch 141/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9675\n",
      "Epoch 142/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9675\n",
      "Epoch 143/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.9675\n",
      "Epoch 144/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9675\n",
      "Epoch 145/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9675\n",
      "Epoch 146/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9675\n",
      "Epoch 147/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9675\n",
      "Epoch 148/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9675\n",
      "Epoch 149/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9675\n",
      "Epoch 150/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9675\n",
      "Epoch 151/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9675\n",
      "Epoch 152/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9675\n",
      "Epoch 153/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9675\n",
      "Epoch 154/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9675\n",
      "Epoch 155/256\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9675\n",
      "Epoch 156/256\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9675\n",
      "Epoch 157/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9675\n",
      "Epoch 158/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9675\n",
      "Epoch 159/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9675\n",
      "Epoch 160/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9675\n",
      "Epoch 161/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9675\n",
      "Epoch 162/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9675\n",
      "Epoch 163/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0760 - accuracy: 0.9675\n",
      "Epoch 164/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9675\n",
      "Epoch 165/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.9675\n",
      "Epoch 166/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9675\n",
      "Epoch 167/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9675\n",
      "Epoch 168/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9675\n",
      "Epoch 169/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9675\n",
      "Epoch 170/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9700\n",
      "Epoch 171/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.9675\n",
      "Epoch 172/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9700\n",
      "Epoch 173/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9675\n",
      "Epoch 174/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9700\n",
      "Epoch 175/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0735 - accuracy: 0.9700\n",
      "Epoch 176/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9700\n",
      "Epoch 177/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9700\n",
      "Epoch 178/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9700\n",
      "Epoch 179/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9700\n",
      "Epoch 180/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9700\n",
      "Epoch 181/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9700\n",
      "Epoch 182/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9700\n",
      "Epoch 183/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9700\n",
      "Epoch 184/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9700\n",
      "Epoch 185/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9700\n",
      "Epoch 186/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9700\n",
      "Epoch 187/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9700\n",
      "Epoch 188/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9700\n",
      "Epoch 189/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9700\n",
      "Epoch 190/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9700\n",
      "Epoch 191/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0710 - accuracy: 0.9700\n",
      "Epoch 192/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.9700\n",
      "Epoch 193/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9700\n",
      "Epoch 194/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9700\n",
      "Epoch 195/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9700\n",
      "Epoch 196/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9700\n",
      "Epoch 197/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9700\n",
      "Epoch 198/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9700\n",
      "Epoch 199/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9700\n",
      "Epoch 200/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9700\n",
      "Epoch 201/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9700\n",
      "Epoch 202/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9700\n",
      "Epoch 203/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9700\n",
      "Epoch 204/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9700\n",
      "Epoch 205/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9700\n",
      "Epoch 206/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9700\n",
      "Epoch 207/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9700\n",
      "Epoch 208/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9700\n",
      "Epoch 209/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9700\n",
      "Epoch 210/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9700\n",
      "Epoch 211/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9700\n",
      "Epoch 212/256\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9700\n",
      "Epoch 213/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9700\n",
      "Epoch 214/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9700\n",
      "Epoch 215/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9700\n",
      "Epoch 216/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9700\n",
      "Epoch 217/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0682 - accuracy: 0.9700\n",
      "Epoch 218/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9700\n",
      "Epoch 219/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9700\n",
      "Epoch 220/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9700\n",
      "Epoch 221/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9700\n",
      "Epoch 222/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.9700\n",
      "Epoch 223/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9700\n",
      "Epoch 224/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9700\n",
      "Epoch 225/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9700\n",
      "Epoch 226/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9700\n",
      "Epoch 227/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0677 - accuracy: 0.9700\n",
      "Epoch 228/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9725\n",
      "Epoch 229/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9700\n",
      "Epoch 230/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9725\n",
      "Epoch 231/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9700\n",
      "Epoch 232/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.9700\n",
      "Epoch 233/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9700\n",
      "Epoch 234/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9700\n",
      "Epoch 235/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9700\n",
      "Epoch 236/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9700\n",
      "Epoch 237/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9700\n",
      "Epoch 238/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9700\n",
      "Epoch 239/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9700\n",
      "Epoch 240/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9700\n",
      "Epoch 241/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9700\n",
      "Epoch 242/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9725\n",
      "Epoch 243/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9725\n",
      "Epoch 244/256\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9700\n",
      "Epoch 245/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9700\n",
      "Epoch 246/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9700\n",
      "Epoch 247/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9700\n",
      "Epoch 248/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9725\n",
      "Epoch 249/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9700\n",
      "Epoch 250/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9725\n",
      "Epoch 251/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9700\n",
      "Epoch 252/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0664 - accuracy: 0.9725\n",
      "Epoch 253/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9700\n",
      "Epoch 254/256\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9725\n",
      "Epoch 255/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9725\n",
      "Epoch 256/256\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9fe4ff2b0>"
      ]
     },
     "execution_count": 792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 256, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_updated = prediction\n",
    "for i in range(0,len(prediction)):\n",
    "    if prediction_updated[i] >=0.85: \n",
    "        prediction_updated[i] = 1\n",
    "    else: \n",
    "        prediction_updated[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. # of Legendaries:  18\n",
      "True # of Legendaries:  30\n"
     ]
    }
   ],
   "source": [
    "print('Pred. # of Legendaries: ', int(sum(prediction_updated)))\n",
    "print('True # of Legendaries: ', int(sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Accuracy =   \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "$$Precision =  \\frac{TP}{TP+FP}$$\n",
    "\n",
    "$$Recall =  \\frac{TP}{TP+FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline Accuracy \n",
    "\n",
    "1 - sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = accuracy_score(y_test, prediction_updated)\n",
    "model_precision = precision_score(y_test, prediction_updated)\n",
    "model_recall = sklearn.metrics.recall_score(y_test, prediction_updated)\n",
    "model_f1 = f1_score(y_test, prediction_updated)\n",
    "model_roc_auc = roc_auc_score(y_test, prediction_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.945\n",
      "Precision:  0.7222222222222222\n",
      "Recall:  0.43333333333333335\n",
      "F1 Score:  0.5416666666666666\n",
      "ROC-AUC:  0.70990990990991\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', model_accuracy)\n",
    "print('Precision: ', model_precision)\n",
    "print('Recall: ', model_recall)\n",
    "print('F1 Score: ', model_f1)\n",
    "print('Precision: ', model_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAHSCAYAAADBmJODAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUCElEQVR4nO3de7SldX3f8c93LnCGgYCCQsBRolBcRGEERIxVoxiJxmpJbWvSroo2i1rpyoUVExvzh/2noTFZLlhtgrc2iklWglXDMo1E8AaKAiICRhNFEEYqV4Fymev59Y+9wXE8gzNzjuz5nrxea521nvPs5zzP9xzOs99nP3vvocYYAQD2fitmPQAAsGtEGwCaEG0AaEK0AaAJ0QaAJkQbAJpYNesBltohT1w5jly3etZjwLL1D9ftN+sRYFnbmAezeWyqhW5bdtE+ct3qXHnxulmPAcvWaYevn/UIsKx9cVy609tcHgeAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmhBtAGhCtAGgCdEGgCZEGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAmRBsAmlg16wFY5jbOp07/TrJ5JFuTvGptxlsOTsZInXNP8rEHkhXJeP2Bya8clHz+odQZ302eOvnVHK/cPzn7ibP9HqCpC8b/ycNZlflUtmVFzqpTZz0Si/SY0a6qg5NcOv30sCTbktw5/fzkMcbmpRqkqn43yRmZ3LX/pzHGJUu1b2Zo38r40BHJ2hXJlpF6zYbkpWuTb2xObtuacdlTkxWV3LX1+1/zvLmMCw6f3cywjPxmXpz7a99Zj8ESecxojzHuTrI+Sarq7UkeGGP8wfbbVFUlqTHG/J4OUVXHJfnFJMcmWZfk41V1zGL2yV6iKllbk+UtI9mSpJJ6/30Zf3ToJNhJcoiLPgA/yh49p11VR1XVDVV1fpJrkqyrqnu3u/11VfXe6fKhVfXhqrq6qq6sqlMW2OVrkvz5GGPzGOPGJLckObGqDqiqv6mqr0yP99o9mZcZ2zZSL7sl9eybkhevSU6YS769JfmrB1Kn3Zr65duSb2130eZLG1On3jJZ//ebZjc3NDeSnJPL8j/GJXnl+Nasx2EJLObhzbFJ3jDGeFNVPdZ+zkvy+2OML1TVkUk+luRZO2xzRJJPb/f5hum6pye5eYzxiiSpqgMXMS+zsrIyLnlqct+21Bu/m3x9U7JpJHOVcfG65K8fSP3GHRl/9ZTk2XMZVx05uZx+6YOpN3w34/NPm/V3AC39Rl6Su2tNDhobc04uy63jgFxfT5r1WCzCYl49fuMY46pd2O5lSc6vqmuTfDTJE6pqzQ7b1AJfN5Jcl+Tnq+qcqnrBGOO+hQ5QVWdOH8lffefd23bne+DxdODKjJ9Zk3zqoeQnVyW/sP9k/SvXJl+bPtI+YMUk2Ely6trJJXX/TWGP3D29q7235vK5HJ5jcs+MJ2KxFhPtB7dbns8Phnduu+XK5EVr66cfR4wxHt5hXxsyeS77EU9JctsY42tJTkry1STvqKrfWWiQMca7xxgnjTFOetLBK/f0++HH4a5tyX3T6D48n/rsQ8lR+ySvWJtcPv01uOLh5OmrJ8t3bE3GmCx/eePkN+uJ3pkIu2tubM2aseXR5RNze26Oi5XdLcmrf8YY81X1vao6OsmNSU7P919lfkmSs5K8M0mqav0Y49oddnFRkv9VVedmEu+nJflSVR2R5K4xxgVV9XCS1y3FvDyO7tia+rXbJ+87mE/Gq/dPfm5txslzqbNuT959b7K2Mv7wyZPtP/ZA6v33T34z5yrj/EMnL2YDdstB2Zi354pkJCsz8qmsy9V12KzHYpGW8iW7v53k45m8iOzvkjzyHoOzkvxxVb1herxPTdc9aozxlar6aJKvZfKWrzdP/xA4Psk5VTWfZHOSNy3hvDwejt034xNP/eH1B67M+OACb+t640EZbzzoxz8XLHPfrf3zpvzcrMdgidV45FLkMnHS8XPjyovX/egNgT1y2uHrZz0CLGtfHJfm/nHPgpcYPVkIAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQxKpZD7DUvnHD/nnF0S+Y9RiwbNW+W2c9Aixvm2qnN3mkDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0MSqWQ/APx5nb/xcnrdtQ+6tufyH/V6TJPmdjZ/JU+bvS5KsHZvzYO2TN+/36lmOCa2dveWKnLLtO7m35nLmvq9Kkrx+y1fy/PkNGancW/vmHaufn3tqvxlPyp54zGhX1cFJLp1+eliSbUnunH5+8hhj81IMUVVPTvKXSZ6b5D1jjF9fiv2yd/nb1c/IRaufmbdsuvzRdf917sWPLp+56ao8WPvMYjRYNj6x8um5aOUx+a0tn3903YWrjs376/gkyT/f+vX8263X57zVz5vViCzCY0Z7jHF3kvVJUlVvT/LAGOMPtt+mqipJjTHmFzHHQ0neluQ5SY5axH7Yi92w8rAcOv/AwjeOkRdtvTm/tea0x3coWGauX3HoD51nD9XqR5fnsjUj9XiPxRLZo+e0q+qoqrqhqs5Pck2SdVV173a3v66q3jtdPrSqPlxVV1fVlVV1yo77G2M8MMb4XJKNOxxnVVVdUFXXT4/3q3syL3u/Z83fnu/Vmty24idmPQosS2dsuTZ/uvEjeem2m/OBVcfNehz20GJeiHZskveNMZ6T5DuPsd15SX5/jHFSkn+V5L27cYwTkxwyxnj2GONZST6wx9OyV3vJlpvy6VU/NesxYNn6k9Xr82/mTs8nVx6ZV2/9h1mPwx5aTLRvHGNctQvbvSzJ+VV1bZKPJnlCVa3ZxWN8M8kxVXVuVZ2W5L6FNqqqM6eP5K/ePDYutAl7sRVjPi/Ydks+s+rIWY8Cy94nVx6ZF87fMusx2EOLifaD2y3PJz/wJMncdsuVyYvW1k8/jhhjPLwrB5g+p35cksuT/GqSd+1ku3ePMU4aY5y0T80ttAl7sRO2/d/cWgfmrhVrZz0KLEuHz9//6PLzt30nt5anobpakrd8jTHmq+p7VXV0khuTnJ7vv8r8kiRnJXlnklTV+jHGtbuy36p6UpKNY4wLq+qmJOcvxbzMxls3fibHbbs9B46N+eCDF+aCfdbn4tVH58Vbb8qnV7s0DkvhP2++PMfN354Dsyl/uvHDuWDVcXnu/G1ZN+7PfCp31Nqcu/rkWY/JHlrK92n/dpKPJ7klyd8l2Xe6/qwkf1xVb5ge71PTdT+gqjYk2S/J6qp6bZJTk6xN8r7pK9TH9Bg0dc52b+/a3h/O/dPHeRJYvn5vnx8+nz7uTTnLRo0xZj3Dkjpw5SHjlP1eNesxYNkaW7fOegRY1r6w6W9y//zdC74vzz9jCgBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATog0ATYg2ADQh2gDQhGgDQBOiDQBNiDYANCHaANCEaANAE6INAE2INgA0IdoA0IRoA0ATNcaY9QxLqqruTPLtWc/BLjskyV2zHgKWOedZL08bYzxpoRuWXbTppaquHmOcNOs5YDlzni0fLo8DQBOiDQBNiDaz9u5ZDwD/CDjPlgnPaQNAEx5pA0ATok2SpKq2VdW1VXVDVV1YVfstYl8/W1Ufmy6/uqre+hjbHlRVb96DY7y9qn5zgfX7VtVfVNU3q+qLVXXk7u4bflyW0Xn2oqq6pqq2VtVrd3e/7DnR5hEPjzHWjzGelWRzkjdtf2NN7PbvyxjjojHGOY+xyUFJdvvO5DH8+yTfG2McleSdSf7bEu4bFmu5nGe3JDkjyZ8t4T7ZBaLNQi5LclRVHVlVX6uqP0pyTZJ1VfXyqrpi+lf2hVW1f5JU1c9X1der6vIkv/jIjqrqjKr679PlQ6vqI1X1lenHzyQ5J8kzpo8+3jHd7i1VdVVVXVdV/2W7fb2tqv6+qi5JcsxOZn9NkvdPlz+U5NTpHeFPV9WV0+NcV1VHL+lPDHZf2/NsjHHzGOO6JPPbr6+qn6yqz253NeGFS/kDQ7TZQVWtSvKKJNdPVx2T5ANjjOckeTDJ7yZ52RjjhCRXJzm7quaSvCfJP0vywiSH7WT35yX5zBjj+CQnJPlqkrcmuXH66OMtVfXyJEcnOTnJ+iQnTi/FnZjkdUmek8md1XN3cowjktyaJGOMrUnuS3JwJo9ozh1jrE9yUpINu/3DgSWyDM6znfnlJBdPz7Pjk1y7m1/Pj7Bq1gOw11hTVY+cYJcleV+Sw5N8e4zxhen6U5Icm+RzVZUk+yS5Iskzk9w0xvhGklTVB5OcucAxXprk3yXJGGNbkvuq6gk7bPPy6ceXp5/vn8mdywFJPjLGeGh6jIt28n3UAuvGdM63VdVTknz4kVnhcbZczrOduSrJ/6yq1Uk+OsYQ7SUm2jzi4elfx4+a3mE8uP2qJJ8YY/zSDtutzySMS6GS/N4Y4107HOPXd/EYG5KsS7Jh+mjmwCT3jDH+rKq+mOQXklxcVb8yxvjkEs0Mu2q5nGcLGmN8tqpelMl5dkFVvWOM8YHFjcr2XB5nd3whyQuq6qgkqar9quqfJPl6kp+qqmdMt/ulnXz9pUn+4/RrV1bVTyT5f5n8df+Ii5O8cbvn8I6oqicn+WyS06tqTVUdkMklwoVclOT10+XXJvnkGGNU1dOTfGuMcd50m+N295uHx0mH82xBVfW0JHeMMd6TyVWEE3bn6/nRRJtdNsa4M5NXjP55VV2XyZ3LM8cYGzO5TPfX0xfI7Oz/svZrSV5SVdcn+VKSnx5j3J3JZcAbpn+V/20mr0i9Yrrdh5IcMMa4JslfZPIc2f/O5NLiQt6X5OCq+maSszN5Li9J/nWSG6aXJp+ZxF//7JU6nGdV9dyq2pDkXyZ5V1V9dXrTzya5tqq+nORfJDl3MT8Lfph/EQ0AmvBIGwCaEG0AaEK0AaAJ0QaAJkQbAJoQbQBoQrQBoAnRBoAm/j/QjE3+nMha0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, prediction_updated)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('True 0s', 'True 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log_reg = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00, 1.00])"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_reg.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.351599996045692"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(model_log_reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45, 0.44, 0.95, 1.03, 0.70, 0.78]])"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Evaluate the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00, 0.00],\n",
       "       [0.93, 0.07],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.97, 0.03],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.60, 0.40],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [0.13, 0.87],\n",
       "       [0.96, 0.04],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.97, 0.03],\n",
       "       [0.90, 0.10],\n",
       "       [0.59, 0.41],\n",
       "       [1.00, 0.00],\n",
       "       [0.65, 0.35],\n",
       "       [0.94, 0.06],\n",
       "       [0.87, 0.13],\n",
       "       [0.95, 0.05],\n",
       "       [0.89, 0.11],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.68, 0.32],\n",
       "       [0.96, 0.04],\n",
       "       [0.91, 0.09],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.09, 0.91],\n",
       "       [0.83, 0.17],\n",
       "       [0.92, 0.08],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.95, 0.05],\n",
       "       [0.51, 0.49],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.95, 0.05],\n",
       "       [0.56, 0.44],\n",
       "       [0.29, 0.71],\n",
       "       [0.95, 0.05],\n",
       "       [1.00, 0.00],\n",
       "       [0.90, 0.10],\n",
       "       [0.75, 0.25],\n",
       "       [1.00, 0.00],\n",
       "       [0.91, 0.09],\n",
       "       [0.93, 0.07],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [0.70, 0.30],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.91, 0.09],\n",
       "       [0.93, 0.07],\n",
       "       [0.95, 0.05],\n",
       "       [1.00, 0.00],\n",
       "       [0.56, 0.44],\n",
       "       [0.96, 0.04],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.66, 0.34],\n",
       "       [0.99, 0.01],\n",
       "       [0.82, 0.18],\n",
       "       [0.98, 0.02],\n",
       "       [0.91, 0.09],\n",
       "       [1.00, 0.00],\n",
       "       [0.93, 0.07],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.37, 0.63],\n",
       "       [0.76, 0.24],\n",
       "       [0.95, 0.05],\n",
       "       [0.11, 0.89],\n",
       "       [0.95, 0.05],\n",
       "       [0.79, 0.21],\n",
       "       [0.92, 0.08],\n",
       "       [0.90, 0.10],\n",
       "       [0.94, 0.06],\n",
       "       [0.67, 0.33],\n",
       "       [0.98, 0.02],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.97, 0.03],\n",
       "       [0.99, 0.01],\n",
       "       [0.71, 0.29],\n",
       "       [1.00, 0.00],\n",
       "       [0.21, 0.79],\n",
       "       [0.94, 0.06],\n",
       "       [0.96, 0.04],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.97, 0.03],\n",
       "       [0.95, 0.05],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.96, 0.04],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.49, 0.51],\n",
       "       [1.00, 0.00],\n",
       "       [0.77, 0.23],\n",
       "       [0.97, 0.03],\n",
       "       [0.98, 0.02],\n",
       "       [0.98, 0.02],\n",
       "       [0.54, 0.46],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.88, 0.12],\n",
       "       [0.21, 0.79],\n",
       "       [0.21, 0.79],\n",
       "       [0.89, 0.11],\n",
       "       [0.40, 0.60],\n",
       "       [0.97, 0.03],\n",
       "       [0.75, 0.25],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [0.78, 0.22],\n",
       "       [0.06, 0.94],\n",
       "       [0.84, 0.16],\n",
       "       [0.33, 0.67],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.83, 0.17],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.86, 0.14],\n",
       "       [0.99, 0.01],\n",
       "       [0.84, 0.16],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.51, 0.49],\n",
       "       [0.98, 0.02],\n",
       "       [0.94, 0.06],\n",
       "       [0.30, 0.70],\n",
       "       [0.63, 0.37],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.03, 0.97],\n",
       "       [1.00, 0.00],\n",
       "       [0.93, 0.07],\n",
       "       [0.93, 0.07],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.44, 0.56],\n",
       "       [0.97, 0.03],\n",
       "       [0.91, 0.09],\n",
       "       [0.96, 0.04],\n",
       "       [0.65, 0.35],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.59, 0.41],\n",
       "       [1.00, 0.00],\n",
       "       [0.86, 0.14],\n",
       "       [0.58, 0.42],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.21, 0.79],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.23, 0.77],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.82, 0.18],\n",
       "       [0.98, 0.02],\n",
       "       [0.92, 0.08],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [0.85, 0.15],\n",
       "       [1.00, 0.00],\n",
       "       [0.21, 0.79],\n",
       "       [1.00, 0.00],\n",
       "       [0.95, 0.05],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.62, 0.38],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.12, 0.88],\n",
       "       [0.96, 0.04],\n",
       "       [0.98, 0.02],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [0.60, 0.40],\n",
       "       [0.89, 0.11],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.99, 0.01],\n",
       "       [0.97, 0.03],\n",
       "       [0.96, 0.04],\n",
       "       [0.82, 0.18],\n",
       "       [0.98, 0.02],\n",
       "       [0.58, 0.42],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.60, 0.40],\n",
       "       [0.02, 0.98],\n",
       "       [1.00, 0.00],\n",
       "       [0.94, 0.06],\n",
       "       [0.95, 0.05],\n",
       "       [0.32, 0.68],\n",
       "       [1.00, 0.00],\n",
       "       [0.90, 0.10],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.16, 0.84],\n",
       "       [0.67, 0.33],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.96, 0.04],\n",
       "       [0.58, 0.42],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.67, 0.33],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.31, 0.69],\n",
       "       [0.99, 0.01],\n",
       "       [0.97, 0.03],\n",
       "       [1.00, 0.00],\n",
       "       [0.84, 0.16],\n",
       "       [0.77, 0.23],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.91, 0.09],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.88, 0.12],\n",
       "       [0.99, 0.01],\n",
       "       [0.95, 0.05],\n",
       "       [0.95, 0.05],\n",
       "       [1.00, 0.00],\n",
       "       [0.93, 0.07],\n",
       "       [0.96, 0.04],\n",
       "       [0.99, 0.01],\n",
       "       [0.99, 0.01],\n",
       "       [0.98, 0.02],\n",
       "       [0.42, 0.58],\n",
       "       [0.98, 0.02],\n",
       "       [0.88, 0.12],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [0.97, 0.03],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [0.94, 0.06],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.84, 0.16],\n",
       "       [1.00, 0.00],\n",
       "       [0.62, 0.38],\n",
       "       [0.98, 0.02],\n",
       "       [0.97, 0.03],\n",
       "       [0.82, 0.18],\n",
       "       [0.89, 0.11],\n",
       "       [0.97, 0.03],\n",
       "       [0.95, 0.05],\n",
       "       [0.98, 0.02],\n",
       "       [0.32, 0.68],\n",
       "       [0.57, 0.43],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [0.95, 0.05],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.95, 0.05],\n",
       "       [0.72, 0.28],\n",
       "       [0.99, 0.01],\n",
       "       [0.47, 0.53],\n",
       "       [1.00, 0.00],\n",
       "       [0.94, 0.06],\n",
       "       [0.66, 0.34],\n",
       "       [1.00, 0.00],\n",
       "       [0.97, 0.03],\n",
       "       [0.33, 0.67],\n",
       "       [0.95, 0.05],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.71, 0.29],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.96, 0.04],\n",
       "       [0.79, 0.21],\n",
       "       [0.81, 0.19],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.98, 0.02],\n",
       "       [0.97, 0.03],\n",
       "       [0.87, 0.13],\n",
       "       [0.08, 0.92],\n",
       "       [0.70, 0.30],\n",
       "       [0.55, 0.45],\n",
       "       [0.93, 0.07],\n",
       "       [1.00, 0.00],\n",
       "       [0.92, 0.08],\n",
       "       [0.99, 0.01],\n",
       "       [1.00, 0.00],\n",
       "       [0.92, 0.08],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.21, 0.79],\n",
       "       [0.69, 0.31],\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00]])"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaynpersonal/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:291: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  indices = (scores > 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "prediction_log_reg = model_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. # of Legendaries:  29\n",
      "True # of Legendaries:  30\n"
     ]
    }
   ],
   "source": [
    "print('Pred. # of Legendaries: ', int(sum(prediction_log_reg)))\n",
    "print('True # of Legendaries: ', int(sum(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = accuracy_score(y_test, prediction_log_reg)\n",
    "model_precision = precision_score(y_test, prediction_log_reg)\n",
    "model_recall = sklearn.metrics.recall_score(y_test, prediction_log_reg)\n",
    "model_f1 = f1_score(y_test, prediction_log_reg)\n",
    "model_roc_auc = roc_auc_score(y_test, prediction_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9325\n",
      "Precision:  0.5517241379310345\n",
      "Recall:  0.5333333333333333\n",
      "F1 Score:  0.5423728813559322\n",
      "ROC-AUC:  0.7490990990990991\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', model_accuracy)\n",
    "print('Precision: ', model_precision)\n",
    "print('Recall: ', model_recall)\n",
    "print('F1 Score: ', model_f1)\n",
    "print('ROC-AUC: ', model_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_log_reg = confusion_matrix(y_test, prediction_log_reg)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm_log_reg)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('True 0s', 'True 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm_log_reg[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
